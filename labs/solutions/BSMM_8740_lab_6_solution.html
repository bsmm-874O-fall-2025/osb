<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Lab 6 – Time Series Methods</title>

  <!-- Jekyll theme CSS from your site -->
  <link rel="stylesheet" href="/osb/assets/main.css">
  
  <style>
    /* Grey solution callouts */
    .solution-box {
      background: #f0f0f0;
      border-left: 4px solid #888;
      padding: 12px 15px;
      margin-bottom: 25px;
      border-radius: 4px;
    }
    .solution-title {
      font-weight: bold;
      margin-bottom: 5px;
    }
    pre {
      background: #f7f7f7;
      padding: 10px 15px;
      border-radius: 6px;
      overflow-x: auto;
      border: 1px solid #ddd;
    }
    /* body {
    font-family: "Times New Roman", Times, serif !important;
  } */

    <style>
  /* Body Text (same as Quarto) */
  body {
    font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
      Helvetica, Arial, sans-serif !important;
  }

  /* Inline code */
  code {
    font-family: "Source Code Pro", monospace !important;
    background: #f5f5f5;
    padding: 2px 4px;
    border-radius: 4px;
  }

  /* Code blocks */
  pre code {
    font-family: "Source Code Pro", monospace !important;
  }

  /* Headings */
  h1, h2, h3, h4, h5 {
    font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
      Helvetica, Arial, sans-serif !important;
  }
</style>

  </style>
  <link rel="stylesheet" href="https://quarto.org/.../quarto-syntax.css">
  <script src="https://quarto.org/.../quarto.js"></script>

</head>

<body>

<header class="site-header" role="banner">
  <div class="wrapper">
    <a class="site-title" href="/osb/">osb</a>
    <nav class="site-nav">
      <div class="trigger">
        <a class="page-link" href="/osb/labs/solutions/BSMM_8740_Q11_solutions.html">BSMM 8740 – Lab 6 Time Series Methods</a>
      </div>
    </nav>
  </div>
</header>

<main class="page-content">
  <div class="wrapper">
    <article class="post">

      <header class="post-header">
        <h1 class="post-title">Lab 6 – Time Series Methods </h1>
      </header>

      <div class="post-content">

        <h2>Introduction</h2>
        <p>
          In today’s lab, you’ll practice building workflows with recipes, parsnip models, rsample cross validations, and model comparison in the context of timeseries data.
          <strong></strong>.
        </p>

        <hr>

        <h2>Packages</h2>
        <pre><code class="language-r">
library(tidyverse)
library(tidymodels)
library(timetk)
library(modeltime)
        </code></pre>

        <hr>

        <h2>The Data</h2>
        <p>The dataset includes daily closing prices for TD, BMO, BNS, RBC, and CM. Load the CSV:</p>

<pre><code class="language-r">
arima_data <- readr::read_csv("data/stock_data.csv", show_col_types = FALSE)
</code></pre>

        <hr>

        <h2>Exercise 1: EDA (Plotting the Data)</h2>
        <p> This question uses data for the closing prices of the five major Canadian banks from 2005-08-10 to 2023-09-29. The data was obtained using the following code (the difference in the time range is due to elimination of rows with NA values:
r
tidyquant::tq_get(
  c("TD","BMO","BNS","RBC","CM")
  , get = "stock.prices"
  , from = "2000-01-01"
  , to = "2023-10-01"
)
The data can be found in your **data** directory
{r}
 </p>
        <p>Plot the data using functions in the timetk package </p>
        <div class="solution-box">
          <div class="solution-title">SOLUTION</div>
          <pre><code class="language-r">
head(arima_data)

arima_long <- arima_data %>%
  pivot_longer(
    cols = c("TD", "BMO", "BNS", "RBC", "CM"),
    names_to = "symbol",
    values_to = "close"
  )

arima_long %>%
  plot_time_series(
    .date_var = date,
    .value = close,
    .color_var = symbol,
    .smooth = FALSE,
    .interactive = FALSE
  )
          </code></pre>
        </div>

        <hr>

        <h2>Exercise 2: Training and Test Split</h2>
        <p>Create test/trains splits of the data, where the **initial period is 10 years** and the **assessment period is 1 year**. Plot the test/train series for CIBC</p>
        <div class="solution-box">
          <div class="solution-title">SOLUTION</div>
          <pre><code class="language-r">
cm_data <- arima_long %>% 
  filter(symbol == "CM") %>% 
  select(date, close)

splits <- time_series_split(
  cm_data,
  initial = "10 years",
  assess = "1 year"
)

splits %>%
  tk_time_series_cv_plan() %>%
  plot_time_series_cv_plan(
    .date_var = date,
    .value = close,
    .title = "Train/Test Split for CM Stock Price"
  )
          </code></pre>
        </div>

        <hr>

        <h2>Exercise 3: Recipe + Model + Workflow</h2>
        <p>Define a data preprocessing **recipe** and a **model** definition. The recipe is based on the formula CM ~ ., and make sure the data argument uses the training data. The model engine should be **auto_arima**. Finally, create a **workflow** object containing the recipe and the model spec, and then **fit** the model using the training data</p>
        <div class="solution-box">
          <div class="solution-title">SOLUTION</div>
          <pre><code class="language-r">
library(recipes)
library(tidymodels)
library(modeltime)   # required for arima_reg()


# Recipe (simple: close ~ date)
time_rec <- recipe(close ~ date, data = training(splits))

# ARIMA model specification
model_spec_arima <- arima_reg() %>%
  set_engine("auto_arima")

# Workflow
workflow_fit_arima <- workflow() %>%
  add_recipe(time_rec) %>%
  add_model(model_spec_arima) %>%
  fit(training(splits))
          </code></pre>
        </div>

        <hr>

        <h2>Exercise 4: Calibration + Forecast</h2>
        <p>Create a **models table** with your fitted model and a **calibration table** that uses the **testing** data. Generate a forecast with the **testing** data and the original **arima_data**. Plot the forecast.</p>
        <div class="solution-box">
          <div class="solution-title">SOLUTION</div>
          <pre><code class="language-r">
# A MODELS TABLE
models_tbl <- modeltime_table(
  workflow_fit_arima
)

# A CALIBRATION TABLE
calibration_tbl <- models_tbl %>%
  modeltime_calibrate(testing(splits))

# PLOT OF THE FITTED MODEL FORECAST OF THE TRAINING DATA
calibration_tbl %>%
  modeltime_forecast(
    new_data    = testing(splits),
    actual_data = cm_data      # original CM series from arima_data
  ) %>%
  plot_modeltime_forecast(
    .title = "ARIMA Forecast for CM (Testing Period)"
  )
          </code></pre>
        </div>

        <hr>

        <h2>Exercise 5: Accuracy Metrics</h2>
        <p>Compute the accuracy metrics for the forecast. What is the $R^2$ (rsq) metric.</p>
        <div class="solution-box">
          <div class="solution-title">SOLUTION</div>
          <pre><code class="language-r">
# compute the metrics here (show your work)

accuracy_tbl <- calibration_tbl %>%
  modeltime_accuracy()

accuracy_tbl   # shows the full accuracy table

# extract only the R-squared value
accuracy_tbl$rsq
          </code></pre>
          <p>The <strong>R²</strong> value (rsq) reported here reflects test forecast performance.</p>
        </div>

        <hr>


        
        <hr>

        <h2>Exercise 5: D is treatment and Y is response varaible</h2>
        <p>Q-12 Execute the following code to create simulated observational data, where D is the treatment variable and Y is the response variable.
{r}
#| echo: true
#| message: false
#| error: false
set.seed(8740)

n <- 800
V <- rbinom(n, 1, 0.2)
W <- 3*V + rnorm(n)
D <- V + rnorm(n)
Y <- D + W^2 + 1 + rnorm(n)
Z <- D + Y + rnorm(n)
data_obs <- tibble::tibble(V=V, W=W, D=D, Y=Y, Z=Z)
In the code below we fit several different outcome models. Compare the resulting coefficients for D. Which regressions appear to lead to unbiased estimates of the causal effect? **(1.5 points)**
{r}
#| echo: true
#| label: outcome models
#
# linear model of Y on X
lin_YX <- lm(Y ~ D, data=data_obs)

# linear model of Y on X and V
lin_YV <- lm(Y ~ D + V, data=data_obs)

# linear model Y on X and W
lin_YW <- lm(Y ~ D + W, data=data_obs)

List all valid adjustment sets for the causal structure in this data (a good first step is to sketch the causal relations between variables - you don't need **ggdag::dagify - just look at the data spec**). **(1.5 points)** ::: 


{#Q12 .callout-note appearance="simple" icon="false"} ## YOUR ANSWER Q12: 1. Regressions that appear to lead to unbiased estimates of the causal effect are: lin\_\_❓ 
2. Valid adjustment sets for the data used in this question are: lin\_\_❓ ::: 
</p>
        <div class="solution-box">
          <div class="solution-title">SOLUTION</div>
          <pre><code class="language-r">
accuracy_tbl <- calibration_tbl %>% modeltime_accuracy()
accuracy_tbl
          </code></pre>
          <p>1 <strong>Only the model that adjusts for V (lin_YV) gives an unbiased effect of D on Y.
This is because V is the real confounder that affects both D and Y, so we need to control for it.</strong> </p>

          
          <p>2 <strong>The only valid adjustment set is {V}.
We should adjust for V, but we should NOT adjust for W (a mediator) or Z (a post-treatment variable).</strong> </p>
        </div>

        <hr>
 <hr>

        <h2>Exercise 13: Spam Classification Dataset</h2>
        <p>## For this question we'll use the [**Spam Classification Dataset**]{.underline} available from the UCI Machine Learning Repository. It features a collection of spam and non-spam emails represented as feature vectors, making it suitable for a logistic regression model. The data is in your data/ directory and the metadata is in the data/spambase/ directory. We'll use this data to create a model for detecting email spam using **logistic regression**.
{r}
#| eval: false
#| message: false
#| label: read the spam data
spam_data <- readr::read_csv('data/spam.csv', show_col_types = FALSE) |> 
  tibble::as_tibble() |> 
  dplyr::mutate(type = forcats::as_factor(type))


::: {#Q13 .callout-note appearance="simple" icon="false"} ## 

YOUR ANSWER Q13: **(1)** Split the data into test and training sets, and create a default recipe and a default model specification. Use the ***glmnet*** engine for the model, with **penalty** = 0.05 & **mixture** = 0.5. **(1 point)**
</p>
        <div class="solution-box">
          <div class="solution-title">SOLUTION</div>
          <pre><code class="language-r">


#| eval: false
#| message: false
#| label: read the spam data
spam_data <- readr::read_csv('data/spam.csv', show_col_types = FALSE) |> 
  tibble::as_tibble() |> 
  dplyr::mutate(type = forcats::as_factor(type))

set.seed(8740)

data_split    <- rsample::initial_split(spam_data, prop = 0.7)
default_train <- rsample::training(data_split)
default_test  <- rsample::testing(data_split)


train <- default_train
test <- default_test
default_recipe <- recipe(type ~ ., data = train) |> 
  step_dummy(all_nominal_predictors())

default_model <- logistic_reg(
  penalty = 0.05,
  mixture = 0.5,
) |>
  set_engine('glmnet')

          </code></pre>
        </div>

        <hr>
  <hr>

        
        <p>create a default workflow object with the recipe and the model specification, fit the workflow using parsnip::fit and the **training** data, and then generate the testing results by applying the fit to the **testing** data using broom::augment .</p>
        <div class="solution-box">
          <div class="solution-title">SOLUTION</div>
          <pre><code class="language-r">

# create a workflow
default_workflow <- workflows::workflow() |>
  workflows::add_recipe(default_recipe) |>
  workflows::add_model(default_model)

# fit the workflow
lm_fit <-
  default_workflow |>
  parsnip::fit(default_train)

# training dataset
#training_results <-
 # broom::augment(lm_fit , default_train)

#testing dataset
testing_results <- broom::augment(lm_fit, new_data = test)
          </code></pre>
         
        </div>

        <hr>

   <hr>

        
        <p>Evaluate the testing results by plotting the **roc_auc curve**, and calculating the **accuracy**.</p>
        <div class="solution-box">
          <div class="solution-title">SOLUTION</div>
          <pre><code class="language-r">

colnames(testing_data)
args(roc_auc)
# compute roc_auc and plot the roc_curve
training_results |>
  yardstick::roc_auc(type, .pred_spam)
training_results |>
  yardstick::roc_curve(type, .pred_spam) |> 
  autoplot()
#awccuracy
training_results |>
  yardstick::accuracy(type, .pred_class)
          </code></pre>
         
        </div>
  <p>This model could be made more accurate by tuning the penalty and mixture hyperparameters using cross-validation (tune_grid).
cross validation tuning of penalty and mixture hyperparameters would increase the accuracy.</p>

        <hr>


    <hr>

        <h2>breif question answer</h2>
        <p>Q14 .callout-note appearance="simple" icon="false"} ## YOUR ANSWER Q14: 1. When preprocessing data for time series models, what is the function timetk::step_fourier() used for? **(1 point)** - The timetk::step_fourier() function is used for: ❓ </p>
        <div class="solution-box">
          <div class="solution-title">SOLUTION</div>
          <pre><code class="language-r">
The timetk::step_fourier() function is used to create Fourier (sine/cosine) features that model complex seasonality patterns in time series data.          </code></pre>
         
        </div>

        <hr>
 <hr>

        
        <p>Q14. 2 .Give an example of its use in a recipe that is engineered for use with weekly data records. **(1 point)** - An example of its use in a recipe that is engineered for use with weekly data records is: ❓
</p>
        <div class="solution-box">
          <div class="solution-title">SOLUTION</div>
          <pre><code class="language-r">

#example of itsuse
#recipe(value ~ date, data = weekly_data) |>
 # timetk::step_timeseries_signature(date) |>
  #timetk::step_fourier(date, period = 52, K = 3)</code></pre>
         
        </div>

        <hr>

  <hr>

        
        <p>Q-15 In a paper in the prestigious **Proceedings of the National Academy of Science** (PNAS) last year: ::: callout-note **S. A. Rains, A. S. Richards**, *US state vaccine mandates did not influence COVID-19 vaccination rates but reduced uptake of COVID-19 boosters and flu vaccines compared to bans on vaccine restrictions*. **Proc. Natl. Acad. Sci.** U.S.A. 121(8), e2313610121 (2024). ::: Rains & Richards performed a causal analysis and found that compared to states that banned COVID-19 vaccination requirements, states that imposed COVID-19 [vaccination mandates]{.underline} exhibit [lower adult and child uptake of flu vaccines and lower uptake of COVID-19 boosters]{.underline}. They included their data and their code (in R), as is best practice. In their analysis, the treatment was binary (vaccine mandate (1) or ban (0)). The proportion of people in a state that had been vaccinated was included to account for the general inclination toward COVID-19 vaccination in a state (mean centered). The outcome variable reflected the proportion of eligible people in a state who had received a booster or flu shot. However, in a letter to the PNAS on September 30, 2024 , the author of the letter, **Jack Fitzgerald,** argued that Rains & Richards had included a **bad control** in their analysis, a variable that biased their results. ::: callout-note **Fitzgerald, J.** *US states that mandated COVID-19 vaccination see higher, not lower, take-up of COVID-19 boosters and flu vaccines*. **Proc. Natl. Acad. Sci.** U.S.A. 121(41), e2403758121 (2024). ::: Here is Fitzgerald's DAG from his letter: 
</p>
  <h2>
YOUR ANSWER Q15: Which variable did Fitzgerald think was the bad control, and why was it bad ?
</h2>
        <div class="solution-box">
          <div class="solution-title">SOLUTION</div>
          <pre><code class="language-r">

#The bad control was the state’s COVID-19 vaccination rate. It was a bad control because the mandate itself affects how many people get vaccinated, and that number then affects flu and booster uptake. Since this variable sits in the middle of the cause-and-effect chain, adjusting for it blocks part of the real effect and biases the results.</code></pre>
         
        </div>

        <hr>


<hr>
  <details>
  <summary style="font-size:18px; cursor:pointer;">
    ....
  </summary>

  <div style="margin-top:15px;">

    <h2>Q1. In time series, partial autocorrelation measures:</h2>
<div class="callout-note" style="border-left:4px solid #999;padding:10px;">
  <strong>Your Answer (Correct Options Marked ✔):</strong><br><br>

  ✔ The direct effect of past values on the current value <br>
  ✖ The total correlation between two points in time <br>
  ✖ The indirect effect of past values on the current value <br>
  ✔ The correlation between two variables, removing the effect of intervening variables
</div>

<hr>

<h2>Q2. In a causal DAG, a confounder is:</h2>
<div class="callout-note" style="border-left:4px solid #999;padding:10px;">
  ✔ A variable that influences both the cause and effect
</div>

<hr>

<h2>Q3. Stationarity in time series analysis means that:</h2>
<div class="callout-note" style="border-left:4px solid #999;padding:10px;">
  ✔ The series has a constant mean and variance over time
</div>

<hr>

<h2>Q4. Precision of this binary classifier is approximately:</h2>
<div style="text-align:center;margin:10px 0;">
  <img src="images/binary_confusion.png" width="250">
</div>

<div class="callout-note" style="border-left:4px solid #999;padding:10px;">
  ✔ 0.75 <br>
  ✖ 0.11 <br>
  ✖ 0.85 <br>
  ✖ 0.58 <br>
  ✖ 0.77
</div>

<hr>

<h2>Q5. In an ARIMA(p, d, q) model, q represents:</h2>
<div class="callout-note" style="border-left:4px solid #999;padding:10px;">
  ✔ The number of lagged forecast errors in the model <br><br>

  ✖ The number of lagged observations included in the model <br>
  ✖ The number of times the raw observations are differenced <br>
  ✖ The number of seasonal periods in the data
</div>

<hr>

<h2>Q6. In causal DAGs, a directed edge represents:</h2>
<div class="callout-note" style="border-left:4px solid #999;padding:10px;">
  ✔ Causation <br><br>

  ✖ Correlation <br>
  ✖ Similarity <br>
  ✖ Distance
</div>

<hr>

<h2>Q7. How does the kNN algorithm perform on large datasets?</h2>
<div class="callout-note" style="border-left:4px solid #999;padding:10px;">
  ✔ It becomes slower due to the increased computation of distances
</div>

<hr>

<h2>Q8. How many open paths are in the DAG?</h2>
<div style="text-align:center;margin:10px 0;">
  <img src="images/dag.png" width="300">
</div>

<div class="callout-note" style="border-left:4px solid #999;padding:10px;">
  ✔ 3 open paths
</div>

<hr>

<h2>Q9. What is the purpose of a soft margin in SVM?</h2>
<div class="callout-note" style="border-left:4px solid #999;padding:10px;">
  ✔ To allow for a certain degree of misclassification in the training data <br><br>

  ✖ To ensure the SVM can only be used for linearly separable data <br>
  ✖ To reduce dimensionality <br>
  ✖ To increase computational efficiency
</div>

<hr>

<h2>Q10. Which stochastic process has the Markov property?</h2>
<div class="callout-note" style="border-left:4px solid #999;padding:10px;">
  ✔ Markov Process (Markov Chain) <br><br>

  ✖ Random Walk
</div>

<hr>



  </div>
</details>




  
        <!-- <p><em>End of Q11 Solutions</em></p> -->

      </div>
    </article>
  </div>
</main>

<footer class="site-footer h-card">
  <div class="wrapper">
    <h2 class="footer-heading"></h2>
  </div>
</footer>

</body>
</html>
